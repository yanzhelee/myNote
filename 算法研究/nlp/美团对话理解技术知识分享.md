# 美团对话理解技术知识分享

智能客服是一种使用自然语言与用户交互的人工智能系统，通过分析用户意图，以人性化的方式与用户沟通，向用户提供客户服务。

本议题首先介绍美团智能客服的对话交互框架，然后就我们在其中意图挖掘、意图理解、情绪识别、对话管理等核心模块中用到的机器学习算法进行详细的介绍。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/1.png)

这是美团线上的一些APP,主要涵盖了生活的方方面面，比如餐饮业务、打车业务、酒店业务等。2018年全年美团的总交易金额达5156.4亿元人民币，同比增加44.3%；2018年美团单日外卖交易笔数超过2100万笔。美团的各个APP上具有大量的客服信息的数据，这也为工程师提供了很好的练兵场。


## 一、智能客服对话框架

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/2.png)

当用户进入到客服这个界面往往是带着一个问题来的，那么我们需要做的就是对这个问题进行理解，然后根据理解去解决他的问题。这里面主要分为两大块，一方面是离线训练和整理知识部分，另一部分是在线处理部分。

在在线部分，首先需要对问题经过基础特征的提取，比如：分词、语义标签抽取、情绪分析、NER识别等；下面的一层就是意图理解层，主要有问题领域分类、意图识别和属性抽取；在意图理解之后就进入到了对话管理这个阶段，对话管理模块主要分类两个部分，状态追踪(DST)和对话决策。

## 二、意图理解

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/3.png)

美团围绕着生活服务有着多个场景和业务，针对业务而言，用户可能是从单一的业务窗口进入到客服中，这时我们是知道该客服服务属于哪个领域，也有可能是从美团的综合门户入口进入到客服中，在这种情况下我们无法判断用户需要进行哪个业务领域方面的咨询。

除此之外，在场景方面，主要涉及单轮QA和多轮Task，针对一些简单的问题，单轮的QA就可以解决，举个例子：

```
U: 美团送餐时间
S: 用户您好，能否配送是以商家营业时间为准的。如您所选的商家正在营业，便代表可以提供点餐及配送服务。
```

而以下复杂的业务通过单轮的QA是无法完成的，所以就需要多轮对话，举个例子：

如何成为美团商家？

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/4.png)

像这种就需要多轮的任务Task才能解决。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/5.png)

由于美团涵盖众多的业务领域，所以当用户提出一个问题时，我们首先要将这个问题进行领域分类,把它分到某个业务领域去，然后用业务的知识去解决这个问题。接下来就是意图分类，根据不同的类别，比如问答类的、闲聊类的采用的方式会有所差异。接下来将对这两方面做详细介绍。

### 2.1 领域分类

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/6.png)

如上图所示,我们首先会从不同的业务库中收集大量的业务数据，作为基础的训练数据，虽然这些数据来自不同的业务库，但是依然存在一些问题，主要有以下两方面：
- 标签不准：用户有可能会在某个业务对话中提问其它领域的问题。
- 领域重叠：某些问题可能会在多个领域中出现。

所以，原始数据不能直接作为训练数据，必须要经过人工筛选和标注方可使用。
为了节约人力成本和提高迭代速度，模型的迭代主要分为如下几步：

1. 搜集业务数据，为每条业务数据打上相应的业务标签
2. 对数据进行模型训练
3. 将上步训练好的模型对样本进行预测
4. 标注人员对预测样本进行标注，选出错误和难分开的样本
5. 返回第2步，对标注好的数据重新进行训练


![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/7.png)

上图就是我们在实践中的模型的效果。
从结果中我们可以看出，BERT的效果是非常高的,但是呢我们也会考虑模型在实际运行中的效率问题。
对于一个15个字左右的query来说，用TextCNN模型在10ms以内就可以解决，如果用BERT模型的话可能需要70ms左右，这个时间还是比较长的，所以在实际上线的时候我们采用的是TextCNN模型。
这是2014年Yoon Kim 提出的一种方法。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/8.png)

### 2.2 意图分类

针对意图分类，主要解决的是问答型和任务型两个方面。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/9.png)

这两类问题有着各自的特点，针对问答类,我们采用检索和相似度排序的策略,下图是问答类的设计架构。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/10.png)

针对任务型的意图理解，我们采用两种方式，一种是通过规则的方式，比如上下文无关文法，另一种是采用模型训练的方式。

**上下文无关文法**

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/11.png)

上图就是其中一个例子，在工业界这种方式还是非常通用的，对于问题冷启动，高频出现的问题和常规的问题，采用规则的方式能够很好的解决。

**多任务学习模型**

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/12.png)

我们把意图分类和属性抽取联合建模，作为一个多任务学习(Multi-task Learning)任务，如上图所示(算法详见Zhang, Xiaodong 2016IJCAI)。双向LSTM处理后，一方面会通过softmax分类输出意图多分类的结果（右边的y^u）；另外通过CRF层，标记每一个词的槽位标签。具体来说，对于“帮我找一家明天中午适合10人聚餐的川菜馆”，模型应该技能识别出来是属于“reserve”订餐的意图，同时又能够抽取出时间、人数和口味菜系等属性信息。 

### 2.3 对话状态追踪(DST)

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/13.png)

DST解决的还是一个意图的问题，在当前上下文的环境或者状态下面明确当前用户的意图。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/14.png)

上图是我们当前的框架，这个session context可以理解为上下文信息，这个信息可能是多个意图的，我们根据其他的一些信息，比如，订单信息、门户信息，入口信息等去明确它是属于哪个领域。

如果这个领域不能明确怎么办？那么我们会跟用户进行一轮的澄清，访问用户一次，来解决这个问题，也就是框架最左边的结构。

领域一旦明确，下一步会进入到意图这一块，我们要明确他当前是什么意图，当然接收到的query也面临多意图判断的问题，同样我们也可以去做澄清，如果明确则继续下面的流程，这是我们整体的架构。

**举个栗子：**

如果接收到一个信息是“牛肉汤撒了”，首选我们要判断它是属于哪个领域的，它是属于外卖商家这个领域，接着判断其意图，对意图进行澄清后得知意图是“如何申请餐损”，然后走餐损的流程。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/15.png)

## 三、知识发现

### 3.1 人在回路


我们的目的是为了解决用户的问题，AI在现有的work flow中节省人力，但是机器解决不了的事情还是要交给人来解决。所以在下图中，我们一定要加一条转人工的服务。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/16.png)

### 3.2 无监督学习在知识发现中应用

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/17.png)

无监督机器学习主要涉及两个问题，一个是句子的语义表示，另一个就是如何做知识聚类。

在语义表示问题上，我们做了大量的试验，在迭代的过程中，我们用到了DSSM模型、seq2seq模型和bert模型来做意图的相似度计算，在这个过程中我们发现不同的模型有各自的特点，它可能抓住不同维度的特征，在离线模型中我们用多个模型的拼接的方式来表示其语义向量。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/18.png)

在知识点聚类这个问题上，我们采用用了最通用的K-means模型来做的。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/19.png)

上面讲到的是意图和说法的挖掘，在实际业务中我们有大量的Task的问题。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/20.png)

根据和用户的交流获取槽信息，每个槽信息后面对应这个不同的接口信息。上图是我们知识库里面一个申请餐损的Task。

在这个环节中我们需要做的就是辅助运营人员构建Task类的知识。

我们根据用户的日志数据中去提取相应意图，然后根据意图共现，回复共现去挖掘，当一个用户问了一个问题之后还会提问哪些问题，当用户收到反馈之后还会反问哪些问题。根据这些去构建Task子树，离线构建好之后交给运营的同学，运营同学审核通过之后就可以上线了。

## 四、情绪识别

### 4.1 背景介绍

客服热线是我们公司对外服务的重要交流通道，在售前、售中和售后的各个环节中发挥着重要作用，为用户提供意见处理、资料管理、技术支持等多项服务。然而目前客服热线在运营过程中还存在一些痛点，如客服人工坐席的服务水平参差导致客户的体验存在差异，另外个别客户还存在动机复杂等问题。因此如何利用技术提升客服热线的服务水平、检测热线中可能的风险是目前需要解决的一个问题。
本项目对客服热线中的语音数据进行挖掘与分析，通过量化用户的情绪能量值，实现对用户情绪状态(是否激动、情感倾向等)的追踪，并且在客户情绪超过设定阈值时提供预警信息，以便相关人员和应急措施的及时介入，从而为相关业务部门提供运营数据支撑和智力支持，最终提升客服热线的服务质量和服务效率。

### 4.2 特征提取

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/21.png)

FTT:短时傅里叶变换

每帧语音都对应于一个频谱（通过短时FFT计算），频谱表示频率与能量的关系

梅尔滤波：实验观测发现人耳就像一个滤波器组一样，它只关注某些特定的频率分量（人的听觉对频率是有选择性的）。也就说，它只让某些频率的信号通过，而压根就直接无视它不想感知的某些频率信号。

### 4.3 模型选择

特征处理完成之后就是采用哪种模型来进行训练。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/22.png)

在迭代中我们采用过传统的机器学习模型，比如LR、SVM模型，神经网络模型，和一些预训练好的模型，在这个里面我们遇到的一个挑战就是，一个情绪是不是激动的标签是针对整个通话记录标注的，但是用户在通话的过程中，不是一直的激动，而是在某个通话阶段情绪激动，而一个标签无法体现出到底是那一部分激动，是全程激动，还是部分激动，还是全程平静的，其实这个里面就涉及到一个弱标签的学习，如下图所示。

![](https://raw.githubusercontent.com/yanzhelee/myNote/master/images/nlp/meituan/23.png)

这是19年提出的一个算法，在实际应用中效果不错，感兴趣的同学可以根据信息去查找。

在实际的效果上，各个模型的表现如下：

MFCC+LSTM < MFCC+CNN < VGGish+ferture level attention < VGGish + decision level attention

## 五、展望

- 多轮上下文建模，意图理解
- 让用户做选择题，意图推荐
- 语音与文本多模态，情绪识别
- 对话历史的话题抽取及切割，坐席助理
